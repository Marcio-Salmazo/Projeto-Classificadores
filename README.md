# Implemeta√ß√£o de classificadores

O reposit√≥rio cont√©m os arquivos fonte referentes √† implemeta√ß√£o das arquiteturas de rede neural ResNet-50 e Vision transformers para a classifica√ß√£o de imagens. No contexto do meu projeto de mestrado, o objetivo √© classificar a imagem facial de roedores quanto √† presen√ßa e intensidade dor. A implementa√ß√£o das arquiteturas √© feita de de forma acess√≠vel e intuitiva, utilizando uma interface gr√°fica via PyQt5 que facilita a explora√ß√£o e aplica√ß√£o dessa tecnologia em diferentes cen√°rios.

A ResNet50 (Residual Network com 50 camadas) √© uma das arquiteturas mais populares e influentes no campo de vis√£o computacional. Sua principal inova√ß√£o √© o uso de conex√µes residuais (skip connections), que permitem que os gradientes fluam com mais facilidade durante o treinamento de redes muito profundas. Esse mecanismo resolve um problema comum em arquiteturas anteriores: a degrada√ß√£o do desempenho √† medida que mais camadas eram adicionadas.

O Vision Transformer representa uma mudan√ßa de paradigma em vis√£o computacional, pois adapta os mecanismos de aten√ß√£o originalmente desenvolvidos para processamento de linguagem natural (os Transformers) ao dom√≠nio de imagens. Em vez de processar uma imagem por meio de convolu√ß√µes, o ViT a divide em pequenos blocos (patches), que s√£o tratados como "palavras visuais". Esses blocos s√£o ent√£o passados por camadas de autoaten√ß√£o, que permitem ao modelo aprender rela√ß√µes globais entre diferentes regi√µes da imagem desde as primeiras etapas do processamento.


## Dados pessoais
**Nome:** Marcio Salmazo Ramos \
**Redes sociais e contato:**

| [![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/marcio-ramos-b94669235) | [![Instagram](https://img.shields.io/badge/-Instagram-%23E4405F?style=for-the-badge&logo=instagram&logoColor=white)](https://www.instagram.com/marcio.salmazo) | [![Gmail](https://img.shields.io/badge/Gmail-333333?style=for-the-badge&logo=gmail&logoColor=red)](mailto:contato.marcio.salmazo19@gmail.com) | [![GitHub](https://img.shields.io/badge/GitHub-0077B5?style=for-the-badge&logo=github&logoColor=white)](https://github.com/Marcio-Salmazo) |
|---|---|---|---|

## Objetivos da atividade

Este trabalho tem como principal objetivo o desenvolvimento de uma ferramenta automatizada, voltada para a detec√ß√£o e classifica√ß√£o de padr√µes faciais que expressam a
presen√ßa de dor em animais. A proposta se baseia na Grimmace Scale associada a t√©cnicas de vis√£o computacional e aprendizado de m√°quina, visando superar as limita√ß√µes dos
m√©todos convencionais, que ainda dependem predominantemente da observa√ß√£o humana
manual. A partir dessa premissa, o desenvolvimento desta aplica√ß√£o se desdobra nos seguintes objetivos espec√≠ficos:

* Preparar dados para treinamento (Separando os grupos de treinamento e teste);
* Construir, compilar e treinar o modelo referente √†s arquiteturas citadas (aplicando os par√¢metros necess√°rios para seu funcionamento);
* Retornar resultados via logs para o Tensorboard, bem como armazenar o arquivo .w5 contendo os pesos aprendidos para an√°lises de desempenho;

## Interface e Funcionalidades
### üìÇ Janela Inicial

A janela inicial do programa √© divida em 2 setores: uma √°rea √† esquerda dedicada √† exibi√ß√£o das mensagens de log (informando sobre o status da opera√ß√£o) e uma √°rea √† direita dedicada √†s funcionalidades do sistema. Em um primeiro momento a √°rea de funcionalidades exige ao usu√°rio a escolha da arquitetura que ser√° utilizada (ViT ou ResNet), por meio de *radiobuttons*. No momento em que o usu√°rio confirma a sele√ß√£o, s√£o apresentados as seguintes funcionalidades (referentes √† arquitetura selecionada):


  - **Selecionar dataset** ‚Äì Permite selecionar a pasta contendo a base de dados para o treinamento. Importante salientar que o diret√≥rio escolhido deve conter subpastas (cada uma representando as diferentes classes). Essa fun√ß√£o exige a defini√ß√£o do tamanho de entrada, tamanho dos lotes (batch) e porcentagem de divis√£o para os dados de valida√ß√£o;
  - **Construir ResNet50** ‚Äì Constr√≥i e compila a arquiteura da rede, definindo os par√¢metros como formato de entrada, modelo base, camadas da rede, fun√ß√µes de ativa√ß√£o, otimizadores, fun√ß√£o custo, dentre outros;  
   - **Construir Modelo ViT** ‚Äì Constr√≥i e compila a arquiteura da rede. Essa fun√ß√£o exige a defini√ß√£o de par√¢metros espec√≠ficos √† ViT, os quais s√£o detalhados na se√ß√£o 'Par√¢metros exigidos pelo programa' deste mesmo documento  
  - **Iniciar treinamento** ‚Äì Inicia o treinamento da rede. Para ter in√≠cio, exige a defini√ß√£o de um nome para o arquivo de log e a quantidade de √©pocas para o treinamento;  
  - **Abrir TensorBoard** ‚Äì Inicia o Tensorboard e abre uma p√°gina na web para exibi√ß√£o dos arquivos de log. Esta fun√ß√£o exige a escolha do diret√≥rio que cont√©m os logs (geralmente est√° em logs/fit na pasta raiz do execut√°vel);  
  - **Fechar programa** ‚Äì encerra a aplica√ß√£o. 


## Par√¢metros exigidos pela ResNet-50
- **Input size** - Tamanho que as imagens devem ser redimensionadas para servir como entrada da rede. O valor inserido definira a altura e largura da imagem;
- **Batch size** - Refere-se ao n√∫mero de amostras de dados que um modelo de aprendizado de m√°quina processa em uma √∫nica itera√ß√£o;
- **Split (treino/valida√ß√£o)** - Define a porcentagem de dados destinados para treino e valida√ß√£o. Exemplo: 0.2 -> 20% para valida√ß√£o e 80% para treino;
- **Nome para logs** - Permite a defini√ß√£o do nome do arquivo de logs gerado ap√≥s o treinamento;
- **√âpocas** - Permite definir a quantidade de √©pocas de treinamento.

## Par√¢metros exigidos pela ViT
- **Input size** - An√°logo ao requisito exigido pela ResNet50;
- **Batch size** - An√°logo ao requisito exigido pela ResNet50;
- **Split (treino/valida√ß√£o)** - ao requisito exigido pela ResNet50;
- **√âpocas** - An√°logo ao requisito exigido pela ResNet50;

- **Patch size** - O tamanho dos blocos (patches) em que a imagem ser√° dividida. Quanto menor o patch, mais detalhes o modelo enxerga desde o in√≠cio, mas tamb√©m aumenta a quantidade de patches a processar (mais custo computacional);
- **Projection Dim** - A dimens√£o do vetor em que cada patch ser√° representado ap√≥s a proje√ß√£o linear (Dimens√µes maiores permitem mais capacidade de representa√ß√£o, mas tamb√©m exigem mais mem√≥ria e poder de processamento);
- **Transform Layers** - N√∫mero de blocos de transformers (compostos por aten√ß√£o + MLP) empilhados no modelo. Quanto mais camadas, mais refinada e abstrata fica a representa√ß√£o;
- **Attention Heads** - Cada camada de aten√ß√£o pode ter v√°rias "cabe√ßas", que aprendem a focar em diferentes aspectos da imagem ao mesmo tempo;
- **MLP Units** - N√∫mero de neur√¥nios nas camadas densas (feed-forward layers) que seguem a parte de aten√ß√£o em cada bloco do transformador. Normalmente √© um valor maior que o 'projection dim'.
- **Nome para logs** - An√°logo ao requisito exigido pela ResNet50;

> üîé **Observa√ß√µes Importantes**  
> - O valor de 'Split' deve estar em nota√ß√£o de ponto flutuante, estritamente entre 0.0 e 1.0;
> - O aplicativo indica valores 'padr√µes' caso o usu√°rio n√£o saiba ao certo o valor de alguns par√¢metros;
> - O diret√≥rio escolhido para o dataset deve conter subpastas (cada uma representando as diferentes classes);  
> - Seguir as vers√µes dos pr√©-requisitos √† risca, uma vez que vers√µes mais novas podem gerar conflitos na IDE.
> - 

## ‚öôÔ∏è Pr√©-requisitos e Instala√ß√£o

- Sistema Operacional: **Windows**;  
- Python **3.9** (recomendado);  
- Tensorflow **2.10.0**;
- Numpy **1.23.5**;
- Scipy **1.13.1**;
- Protobuf **3.20.2**;
- Tensorboard **2.10.1**;
- Pillow (Sem vers√£o espec√≠fica, pode ser a mais atual);
- CUDA 11.2 (Para uso da GPU);
- CuDNN 8.1 (Para uso da GPU).

---

## Tutorial para instalar GPU para TensorFlow no Windows

1. **Desinstalar pacotes conflitantes (opcional, mas recomendado):** utilizar o comando *pip uninstall tensorflow tensorflow-gpu tensorflow-intel* ou desinstalar manualmente via explorador do windows;
2. **Instalar TensorFlow GPU 2.10:** vers√£o da biblioteca espec√≠fica para esta implementa√ß√£o;
3. **Baixar & instalar CUDA 11.2:** Download oficial pelo site da NVIDIA *https://developer.nvidia.com/cuda-11.2.0-download-archive*;
4. **Baixar cuDNN 8.1 para CUDA 11.2:** Requer login NVIDIA Developer (gratuito) e pode ser acessado pelo link *https://developer.nvidia.com/rdp/cudnn-archive#a-collapse811-110*. O resultado do download ser√° um arquivo .ZIP;
5. **Copiar conte√∫do das pastas baixadas (cuDNN 8.1):** √â necess√°rio extrair o conte√∫do compactado e mover o conte√∫do das pastas, seguindo o seguinte esquema:

conte√∫do da pasta **bin**  ‚Üí C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\bin\
conte√∫do da pasta **lib**  ‚Üí C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\lib\x64\
conte√∫do da pasta **include** ‚Üí C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\include

6. **Adicionar ao PATH:** Adicionar as seguintes entradas ao PATH do Windows e reiniciar o computador:

C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\bin\
C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.2\libnvvp

7. **Testar o download:** Abrir o console python e inserir os seguintes comandos:

import tensorflow as tf\
print(tf.config.list_physical_devices('GPU'))

Se o resultado for algo como *[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]*, indica que o processo foi realizado com sucesso.

---

## Estrutura de base de dados padr√£o para utiliza√ß√£o

Para que o programa reconhe√ßa devidamente a base de dados, √© necess√°rio seguir a seguinte estrutura:

‚îú‚îÄ‚îÄ Diret√≥rio contendo a base de dados (Arquivos .png)/\
‚îú‚îÄ‚îÄ Classe 1 (Diret√≥tio)/\
‚îÇ   ‚îî‚îÄ‚îÄ Conjunto de imagens (Arquivos .png)/\
‚îú‚îÄ‚îÄ Classe 2 (Diret√≥tio)/\
‚îÇ   ‚îî‚îÄ‚îÄ Conjunto de imagens (Arquivos .png)/\
‚îÇ   ...\
‚îú‚îÄ‚îÄ Classe N (Diret√≥tio)/\
‚îÇ   ‚îî‚îÄ‚îÄ Conjunto de imagens (Arquivos .png)/\


---

## ‚ñ∂Ô∏è Modo de Uso

1. Abrir o diret√≥rio em uma IDE python de sua prefer√™ncia e criar um novo ambiente virtual (recomendo o PyCharm Community Edition);
2. Instalar os pacotes requeridos pela aplica√ß√£o (Ver se√ß√£o de pr√©-requisitos);
3. Executar o arquivo main.py;
4. Carregar um diret√≥rio contendo uma base de dados e definir os par√¢metros exigidos. Levar em considera√ß√£o a estrutura de arquivos exigida (Ver se√ß√£o anterior); 
5. Construir a estrutura da arquitetura
6. Iniciar o treinamento, definindo os par√¢metros exigidos
7. Aguardar at√© o encerramento do treino para obter o arquivo de pesos e logs

---

## Bugs conhecidos

* N/A

---

## Testes de confiabilidade

A fim de garantir que as implementa√ß√µes das arquiteturas ResNet-50 e Vision Transformer (ViT) funcionam corretamente e geram resultados compat√≠veis com aqueles reportados na literatura cient√≠fica, foi desenvolvida uma etapa formal de valida√ß√£o externa do c√≥digo.
Esses testes avaliam a fidelidade da implementa√ß√£o, e n√£o o desempenho no dataset real de roedores (que possui caracter√≠sticas bem distintas). Os testes foram conduzidos utilizando datasets p√∫blicos e padronizados, seguindo protocolos de artigos de refer√™ncia, confirmando se os modelos foram corretamente:

* Constru√≠dos
* Compilados
* Treinados
* Avaliados
* Integrados com TensorBoard e callbacks
* Processados dentro do fluxo do *tf.data.Dataset*

Os arquivos referentes aos testes aplicados para a arquiteura ResNet50 est√£o alocados em *".\Mestrado\Projeto-Classificadores\resnet_network_validation"*, j√° os arquivos referentes aos testes aplicados para a arquiteura ViT est√£o alocados em *".\Mestrado\Projeto-Classificadores\vit_network_validation"*.

1. **Confiabilidade da implementa√ß√£o ViT (Vision Transformer):**

* ***Artigo de refer√™ncia utilizado:*** Barman et al., 2024 ‚Äì ‚ÄúSkin Cancer Segmentation and Classification Using Vision Transformer‚Äù
* ***Dataset utilizado:*** HAM10000 ‚Äî Human Against Machine Skin Lesion Dataset, amplamente utilizado em pesquisas de dermatologia computacional.
* ***Protocolo seguido:*** Para permitir compara√ß√£o justa com experimentos da literatura e testar a robustez da implementa√ß√£o ViT, foi conduzido o seguinte procedimento:

        A - Input: 224√ó224
        B - Patch size: 16√ó16
        C - Proje√ß√£o: 64
        D - 8 camadas Transformer
        E - 4 cabe√ßas de aten√ß√£o
        F - MLP interno: 128 unidades
        G - Treinamento por 50 √©pocas
        H - Otimizador: Adam (5e-5)
        I - Loss: categorical crossentropy com label smoothing (0.1)
        J - Divis√£o trein/val/test conforme metadados oficiais

* O objetivo do teste foi Verificar se a implementa√ß√£o da ViT produz curvas de treino est√°veis, n√£o explode e/ou n√£o entra em colapso, gera distribui√ß√µes corretas de predi√ß√µes e se alcan√ßa acur√°cia e F1-macro dentro da faixa esperada para ViT ‚Äúpuro‚Äù sem pretraining espec√≠fico em dermatologia. Os resultados obtidos podem ser conferidos no arquivo localizado em *"\Projeto-Classificadores\vit_network_validation\Readme_ViT_Tests.rtf"*

2. **Confiabilidade da implementa√ß√£o ResNet-50 (CheXpert):**

* ***Artigo de refer√™ncia utilizado:*** Irvin et al., 2019 ‚Äì ‚ÄúCheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels and Expert Comparison‚Äù (artigo oficial do dataset CheXpert)
* ***Dataset utilizado:*** CheXpert-small, vers√£o de 200 mil imagens reduzida para testes acad√™micos.
* ***Protocolo seguido:*** O teste foi conduzido seguindo rigorosamente o pipeline padr√£o usado na literatura para treinar CNNs em CheXpert:

        A - Input: 320√ó320
        B - Loss: Binary Crossentropy
        C - Otimizador: Adam 3e-5
        D - Final layer sigmoidal (multi-label)
        E - AUC calculado por estudo, n√£o por imagem
        F - Pol√≠tica para incertezas: U-Zeros
        G - M√©trica n√£o inclu√≠da no compile() (como no artigo), calculada externamente a cada √©poca
        H - Treinamento por 3 √©pocas (curto, mas suficiente para valida√ß√£o de consist√™ncia)

Objetivo do teste foi confirmar se sua implementa√ß√£o da ResNet-50 executa o pipeline CheXpert corretamente, calcula AUC por estudo de forma id√™ntica ao artigo, converge adequadamente j√° nos primeiros ciclos e produz curvas loss/val_loss coerentes. Os resultados obtidos podem ser conferidos no arquivo localizado em *".\Projeto-Classificadores\resnet_network_validation\Readme_Resnet_Tests.rtf"*

---

## ‚ö†Ô∏è Erros Comuns

| Erro | Causa prov√°vel | Solu√ß√£o |
|------|----------------|---------|
| ‚ùå Erro ao abrir base de dados | Estrutura de arquivos inv√°lida | Verifique se o diret√≥rio cont√©m as subpastas como categorias |
| ‚ùå Aplicativo n√£o abre | Python ou depend√™ncias ausentes | Reinstale depend√™ncias |
| ‚ùå Travamento ou fechamento inesperado | Instabilidade de c√≥digo | Contatar desenvolvedor |

---

## üÜï Atualiza√ß√µes / Changelog

- **v0.5.0**
  - Vers√£o inicial, contemplando a unifica√ß√£o de ambas as arquiteturas em um √∫nico programa

- **v0.9.0**
  - Corre√ß√£o de bugs para o treinamento da ViT (Que fechava sozinho ap√≥s o treino);
  - Aumento da robustez dos modelos e otimiza√ß√£o do fluxo de treinamento;
  - Implemeta√ß√£o de algoritmos e protocolos para garantir a confiabilidade das redes (utilizando a literatura cient√≠fica como base);
  - Maior grau de documenta√ß√£o do c√≥digo (via coment√°rios) e documentos separados para explica√ß√£o de implementa√ß√µes e resultados.
---

## üë®‚Äçüíª Autores / Contribuidores

- Marcio Salmazo Ramos (Desenvolvedor)
- Maur√≠cio Cunha Escarpinati (Orientador - UFU) 
- Daniel Duarte Abdala (Co-orientador - UFU)  

